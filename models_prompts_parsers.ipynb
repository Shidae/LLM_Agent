{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import OpenAI as LangChainOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.clear_all_output()",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "display(Javascript('IPython.notebook.clear_all_output()'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env variables\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI model instance using LangChain\n",
    "llm = LangChainOpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the  model to generate a joke\n",
    "joke = llm(\"Tell me a joke\")\n",
    "joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for evaluating sentiment and subject\n",
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "text: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using LangChain's ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLMChain with the prompt and the model\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment and subject of the input text\n",
    "output = chain.predict(input=\"I created a AI automated Chatbot today and it was okay\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative new version\n",
    "# this creates a runnable sequence that first processes the input through the prompt_template\n",
    "# and then passes the result to the llm\n",
    "chain = prompt_template | llm\n",
    "# invoke method uses this chain\n",
    "output = chain.invoke({\"input\": \"I created an AI automated Chatbot today and it was okay.\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World example with ResponseSchema, Templates, Chains and OutputParsers\n",
    "`There were two issues with the output: It contains text and the output is just a string instead of a dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define response schema (structured output) for parsing\n",
    "# key and value pair for sentiment, subjectm and price schema\n",
    "# description defined as // in the format_instructions\n",
    "sentiment_schema = ResponseSchema(\n",
    "    name=\"sentiment\",\n",
    "    description=\"Is the text positive, neutral or negative? Only provide these words.\"\n",
    ")\n",
    "\n",
    "subject_schema = ResponseSchema(\n",
    "    name=\"subject\",\n",
    "    description=\"What subject is the text about? Use exactly one word.\"\n",
    ")\n",
    "price_schema = ResponseSchema(\n",
    "    name=\"price\",\n",
    "    description=\"How expensive was the product? Use None if no price was provided in the text.\"\n",
    ")\n",
    "# list\n",
    "response_schemas = [sentiment_schema, subject_schema, price_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the structured output parser\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get format instructions for the parser\n",
    "format_instructions = parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template with format instructions included\n",
    "template = \"\"\"\n",
    "Interprete the text and evaluate the text.\n",
    "sentiment: is the text in a positive, neutral or negative sentiment?\n",
    "subject: What subject is the text about? Use exactly one word.\n",
    "price: How expensive was the product? Use None if no price was provided in the text.\n",
    "\n",
    "Just return the JSON, do not add ANYTHING, NO INTERPRETATION!\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "text: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escape the format_instructions string\n",
    "# treat {} as literal text for e.g. {'sentiment': 'positive', 'subject': 'food', 'price': 'None'}\n",
    "escaped_format_instructions = format_instructions.replace('{', '{{').replace('}', '}}')\n",
    "\n",
    "# Format the messages with input and format instructions\n",
    "messages = prompt.format_messages(\n",
    "    input=\"I ordered Chicken and Coleslaw from Texas it was spicy.\",\n",
    "    format_instructions=escaped_format_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI chat model with zero temperature for deterministic output\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "response = chat(messages)\n",
    "parsed_output = parser.parse(response.content)\n",
    "parsed_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
