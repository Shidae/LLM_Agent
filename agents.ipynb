{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Laden Sie die Umgebungsvariablen aus der .env-Datei\n",
    "load_dotenv()\n",
    "API_KEY = os.environ.get(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load vectorDB\n",
    "# with open(\"faiss_store.pkl\", \"rb\") as f:\n",
    "#     vectorstore = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index(\"faiss_index.pkl\")\n",
    "\n",
    "# Load the docstore and index_to_docstore_id\n",
    "with open(\"faiss_store.pkl\", \"rb\") as f:\n",
    "    docstore_dict, index_to_docstore_id = pickle.load(f)\n",
    "\n",
    "# Convert the docstore dict to an InMemoryDocstore\n",
    "# FAISS expects Docstore object instead of dict to use methods like search()\n",
    "docstore = InMemoryDocstore(docstore_dict)\n",
    "\n",
    "# Initialize the embedding function\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "\n",
    "# Recreate the FAISS object\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents use an LLM to determine which actions to perform and in what order. An action can be either using a tool and observing its output or returning it to the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools are functions that agents can use to interact with the world. These tools can be common utilities (e.g. search, math etc.), other chains, or even other agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000214DE25FD10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000214DE2A5190>, openai_api_key=SecretStr('**********'), openai_proxy='')))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000214DE25FD10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000214DE2A5190>, openai_api_key=SecretStr('**********'), openai_proxy='')))>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# initialize LLM\n",
    "llm = ChatOpenAI(openai_api_key=API_KEY, model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "\n",
    "# built-in tool in LangChain for math calc.\n",
    "tool_names = [\"llm-math\"]\n",
    "# math tool is made available to llm to use\n",
    "tools = load_tools(tool_names, llm=llm)\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "# our toolbox\n",
    "tool_list = [\n",
    "    Tool(\n",
    "        name = \"Math Tool\",\n",
    "        # run method of the first and only tool loaded \"llm_math\"\n",
    "        func=tools[0].run,\n",
    "        description=\"Tool to calculate, nothing else\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\shahi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question doesn't require a calculation, so I'll just respond with an answer.\n",
      "Action: \n",
      "Final Answer: I am here to assist you with any calculations you need.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am here to assist you with any calculations you need.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "# creates an agent, it uses tool_list, llm, agent type which can use tools without prior examples\n",
    "agent = initialize_agent(tool_list, \n",
    "                         llm, \n",
    "                         agent=\"zero-shot-react-description\", \n",
    "                         verbose=True,\n",
    "                         )\n",
    "agent.run(\"How are you? Can you calculate for me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Math Tool to calculate this division.\n",
      "Action: Math Tool\n",
      "Action Input: {'expression': '100/25'}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 4.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 4.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is 100 devided by 25?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create your own tools by creating a class that inherits from BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from pydantic import Field\n",
    "\n",
    "# creates a new class that inherits from BaseTool.\n",
    "# BaseTool class allows creating custom tools.\n",
    "class CustomSearchTool(BaseTool):\n",
    "\n",
    "    # properties for agent to understand when and how to use this tool\n",
    "    name = \"restaurant search\"\n",
    "    description = \"useful for when you need to answer questions about our restaurant\"\n",
    "\n",
    "    # pydantic uses field declaration to validate that the passed object is a FAISS vectorstore\n",
    "    # and assigns it to the vectorstore attribute of the CustomSearchTool\n",
    "    vectorstore: FAISS = Field(description=\"Vector store for restaurant information\")\n",
    "\n",
    "    # method defines what happens when the tool is used. It takes a query string and\n",
    "    # optional run manager as arguments.\n",
    "    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "        docs = self.vectorstore.similarity_search(query, k=4)  # Get top 4 relevant documents\n",
    "\n",
    "        # extracts the content from each retrieved document and joins them into a single string\n",
    "        # separated by new lines\n",
    "        text_list = [doc.page_content for doc in docs]\n",
    "        return \"\\n\".join(text_list)\n",
    "    \n",
    "    # async method is a placeholder for an asynchronous version of the tool.\n",
    "    # it's not used and will raise error if called.\n",
    "    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "# vectorstore attribute is set when creating instance of CustomSearchTool\n",
    "tools = [CustomSearchTool(vectorstore=vectorstore)]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the restaurant search tool to find the opening hours of the restaurant.\n",
      "Action: restaurant search\n",
      "Action Input: \"restaurant hours\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mQ: What are the hours of operation for your restaurant?\n",
      "A: Our restaurant is open from 11 a.m. to 10 p.m. from Monday to Saturday. On Sundays, we open at 12 p.m. and close at 9 p.m.\n",
      "\n",
      "Q: What type of cuisine does your restaurant serve?\n",
      "A: Our restaurant specializes in contemporary American cuisine with an emphasis on local and sustainable ingredients.\n",
      "Q: Do you have any specials or promotions running currently?\n",
      "A: Yes, we have a Happy Hour promotion from 3 to 5 p.m. on weekdays, with special prices on selected appetizers and drinks.\n",
      "Q: What steps is your restaurant taking to ensure safety amid the ongoing pandemic?\n",
      "A: We adhere to strict health and safety protocols, including regular sanitization, maintaining physical distance between tables, and providing hand sanitizers for customers. We also offer contactless pickup and delivery options.\n",
      "Q: Do you offer vegetarian or vegan options?\n",
      "A: Yes, we have a range of dishes to cater to vegetarians and vegans. Please let our staff know about any dietary restrictions you have when you order.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered all the necessary information about the restaurant.\n",
      "Final Answer: The restaurant opens at 11 a.m. to 10 p.m. from Monday to Saturday, and 12 p.m. to 9 p.m. on Sundays.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The restaurant opens at 11 a.m. to 10 p.m. from Monday to Saturday, and 12 p.m. to 9 p.m. on Sundays.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"When does the restaurant open?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
